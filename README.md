<div align="center">

# self-learning-viral-agent

**An autonomous AI agent that grows your Threads account by researching viral content, generating posts, and continuously learning from what works.**

Built with [LangGraph](https://github.com/langchain-ai/langgraph) &bull; Powered by Claude &bull; Human-in-the-loop via Telegram

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Tests](https://img.shields.io/badge/tests-20%20passed-brightgreen.svg)](#tests)
[![LangGraph](https://img.shields.io/badge/LangGraph-0.3+-orange.svg)](https://github.com/langchain-ai/langgraph)

</div>

---

Most social media bots just post on a schedule. This agent **learns**. It studies what goes viral in your niche, extracts the patterns behind it, generates posts using those patterns, publishes them, measures the results, and feeds everything back into its strategy. Every cycle makes it smarter.

```
Day 1:  "Here's a generic coding tip"           â†’ 12 likes
Day 7:  "Hot take: most devs don't need Docker"  â†’ 340 likes
Day 14: Agent learned contrarian hooks work 3x    â†’ adapts strategy automatically
```

## How It Works

The system runs two independent pipelines that share a knowledge base:

```mermaid
graph TB
    subgraph "Pipeline 1: Content Creation (runs 2-3x/day)"
        A[Goal Check] -->|not reached| B[Research Viral Content]
        A -->|100 followers reached| Z[Done!]
        B --> C[Extract Patterns]
        C --> D[Generate 5 Post Variants]
        D --> E[Multi-Signal Ranking]
        E --> F{Human Approval<br/>via Telegram}
        F -->|Approve/Edit| G[Publish to Threads]
        F -->|Reject| D
        G --> H[Schedule Metrics Check]
    end

    subgraph "Pipeline 2: Learning Loop (runs daily)"
        I[Collect Metrics] --> J[Analyze Performance]
        J --> K[Update Pattern Scores]
        K --> L[Adjust Strategy]
    end

    H -.->|shared knowledge base| I
    L -.->|improved strategy| B

    style A fill:#4A90D9,stroke:#333,color:#fff
    style F fill:#E8A838,stroke:#333,color:#fff
    style G fill:#50C878,stroke:#333,color:#fff
    style L fill:#9B59B6,stroke:#333,color:#fff
    style Z fill:#50C878,stroke:#333,color:#fff
```

### Why Two Pipelines?

Posts need **24-48 hours** to accumulate meaningful engagement data. You can't research, post, and learn in one loop. The creation pipeline runs multiple times per day, while the learning pipeline runs once daily on yesterday's data â€” then feeds improved strategy back into creation.

## The Self-Learning Loop

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   Research         What's going viral right now?        â”‚
â”‚      â†“                                                  â”‚
â”‚   Extract          Why is it going viral?               â”‚
â”‚      â†“             (patterns, hooks, structures)        â”‚
â”‚   Generate         Create posts using those patterns    â”‚
â”‚      â†“                                                  â”‚
â”‚   Rank             AI score + historical data + novelty â”‚
â”‚      â†“                                                  â”‚
â”‚   Publish          Post the winner                      â”‚
â”‚      â†“                                                  â”‚
â”‚   Measure          Wait 24h, collect engagement data    â”‚
â”‚      â†“                                                  â”‚
â”‚   Learn            What worked? What didn't? Why?       â”‚
â”‚      â†“                                                  â”‚
â”‚   Adapt            Update strategy, adjust weights      â”‚
â”‚      â”‚                                                  â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Feed back into Research â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Multi-Signal Ranking

Posts aren't ranked by AI vibes alone. Each variant gets a **composite score** from three independent signals:

```
composite = 0.4 Ã— ai_score + 0.3 Ã— pattern_history + 0.3 Ã— novelty
```

| Signal | What it measures | How |
|--------|-----------------|-----|
| **AI Score** (0-10) | Viral potential: hook strength, emotional trigger, shareability | Claude evaluates each variant |
| **Pattern History** (0-10) | How well this pattern performed in the past | Cumulative engagement data from knowledge base |
| **Novelty** (0-10) | How different this is from recent posts | Cosine distance of embeddings vs last 20 posts |

New patterns get a **5.0 exploration bonus** for history score â€” the system balances exploitation (use what works) with exploration (try new things).

## Human-in-the-Loop

The agent never posts without your approval. When a post is ready:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“± Telegram Bot                         â”‚
â”‚                                          â”‚
â”‚  New Post for Approval (Cycle #7)        â”‚
â”‚  Followers: 43                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”‚
â”‚  Hot take: 90% of "clean code"           â”‚
â”‚  advice makes your code slower.          â”‚
â”‚                                          â”‚
â”‚  The fastest code is the code that       â”‚
â”‚  doesn't exist. Ship less, ship faster.  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”‚
â”‚  Pattern: contrarian_hot_take            â”‚
â”‚  Score: 7.8/10                           â”‚
â”‚                                          â”‚
â”‚  [âœ… Approve] [âœï¸ Edit] [âŒ Reject]       â”‚
â”‚                                          â”‚
â”‚  Alternatives:                           â”‚
â”‚  [ğŸ“ Use Alt 1]  [ğŸ“ Use Alt 2]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Built on LangGraph's `interrupt()` mechanism â€” the graph pauses, saves state, and resumes when you respond. Even if the server restarts.

## Quick Start

### Prerequisites

- Python 3.12+
- [uv](https://docs.astral.sh/uv/) (recommended) or pip
- An [Anthropic API key](https://console.anthropic.com/)

### Setup

```bash
# Clone
git clone https://github.com/yourusername/self-learning-viral-agent.git
cd self-learning-viral-agent

# Install dependencies
uv sync

# Configure
cp .env.example .env
# Edit .env â†’ set ANTHROPIC_API_KEY (minimum required)
```

### Run Your First Cycle

```bash
# Interactive mode â€” you approve/reject posts in the terminal
uv run python scripts/manual_run.py

# Auto-approve mode (for testing the full pipeline)
uv run python scripts/manual_run.py --auto-approve

# Run the learning pipeline
uv run python scripts/manual_run.py --pipeline learning
```

The first run uses **mock APIs** â€” no Threads account needed. You'll see the full pipeline execute with fake but realistic data.

### Health Check

```bash
uv run python scripts/check_health.py
```

## Architecture

```
self-learning-viral-agent/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ account_niche.yaml       # Your niche, voice, audience, content pillars
â”‚   â””â”€â”€ settings.py              # Environment config (pydantic-settings)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/                  # Pydantic models + TypedDict states
â”‚   â”‚   â”œâ”€â”€ state.py             # Graph state schemas (the data flowing through)
â”‚   â”‚   â”œâ”€â”€ research.py          # ViralPost, ContentPattern
â”‚   â”‚   â”œâ”€â”€ content.py           # PostVariant, RankedPost
â”‚   â”‚   â”œâ”€â”€ publishing.py        # PublishedPost, PostMetrics
â”‚   â”‚   â””â”€â”€ strategy.py          # AccountNiche, ContentStrategy, PatternPerformance
â”‚   â”‚
â”‚   â”œâ”€â”€ graphs/                  # LangGraph pipeline definitions
â”‚   â”‚   â”œâ”€â”€ creation_pipeline.py # Graph 1: research â†’ generate â†’ approve â†’ publish
â”‚   â”‚   â””â”€â”€ learning_pipeline.py # Graph 2: metrics â†’ analyze â†’ learn â†’ adapt
â”‚   â”‚
â”‚   â”œâ”€â”€ nodes/                   # Individual pipeline steps
â”‚   â”‚   â”œâ”€â”€ goal_check.py        # Check follower count vs target
â”‚   â”‚   â”œâ”€â”€ research.py          # Find viral content (Reddit + Threads)
â”‚   â”‚   â”œâ”€â”€ patterns.py          # LLM extracts reusable patterns
â”‚   â”‚   â”œâ”€â”€ generation.py        # LLM generates 5 post variants
â”‚   â”‚   â”œâ”€â”€ ranking.py           # Multi-signal scoring (AI + history + novelty)
â”‚   â”‚   â”œâ”€â”€ approval.py          # Human-in-the-loop via interrupt()
â”‚   â”‚   â”œâ”€â”€ publishing.py        # Publish to Threads API
â”‚   â”‚   â”œâ”€â”€ metrics.py           # Collect engagement data
â”‚   â”‚   â”œâ”€â”€ analysis.py          # LLM analyzes what worked
â”‚   â”‚   â”œâ”€â”€ learning.py          # Update pattern performance records
â”‚   â”‚   â””â”€â”€ strategy.py          # LLM adjusts overall strategy
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/                   # External service wrappers (mock-first)
â”‚   â”‚   â”œâ”€â”€ threads_api.py       # Threads publish + metrics (Mock + Real)
â”‚   â”‚   â”œâ”€â”€ reddit_client.py     # PRAW viral content research
â”‚   â”‚   â”œâ”€â”€ apify_client.py      # Threads scraping via Apify
â”‚   â”‚   â””â”€â”€ embeddings.py        # Novelty scoring via cosine similarity
â”‚   â”‚
â”‚   â”œâ”€â”€ prompts/                 # All LLM prompt templates
â”‚   â”œâ”€â”€ store/                   # Knowledge base (LangGraph Store wrapper)
â”‚   â”œâ”€â”€ orchestrator.py          # APScheduler (cron-like scheduling)
â”‚   â””â”€â”€ persistence.py           # Checkpointer + Store factory
â”‚
â”œâ”€â”€ bot/                         # Telegram approval bot
â”‚   â”œâ”€â”€ telegram_bot.py          # Bot setup + message formatting
â”‚   â”œâ”€â”€ handlers/                # Approve/Edit/Reject callbacks
â”‚   â””â”€â”€ webhook.py               # FastAPI webhook endpoint
â”‚
â”œâ”€â”€ api/                         # FastAPI server
â”‚   â””â”€â”€ main.py                  # Health + status + webhook endpoints
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ manual_run.py            # Run a single cycle (interactive or auto)
â”‚   â”œâ”€â”€ init_account.py          # Initialize niche config in store
â”‚   â””â”€â”€ check_health.py          # Verify everything is connected
â”‚
â””â”€â”€ tests/                       # 20 tests covering nodes, tools, graph compilation
```

## Knowledge Base

Both pipelines share a persistent knowledge base via [LangGraph Store](https://langchain-ai.github.io/langgraph/concepts/persistence/#store) â€” a key-value store with namespace separation:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 LangGraph Store                  â”‚
â”‚                                                  â”‚
â”‚  config/             Account niche & voice       â”‚
â”‚  strategy/           Current content strategy    â”‚
â”‚  pattern_performance/ Which patterns work best   â”‚
â”‚  published_posts/    Full post history           â”‚
â”‚  pending_metrics/    Posts awaiting measurement  â”‚
â”‚  metrics_history/    Engagement data over time   â”‚
â”‚  research_cache/     Cached viral content (24h)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

In development: `InMemoryStore`. In production: `AsyncPostgresStore` with embedding support for semantic search.

## Configuring Your Niche

Edit `config/account_niche.yaml` to match your account:

```yaml
niche: "tech"
sub_niche: "programming & startups"

voice:
  tone: "conversational, insightful, slightly provocative"
  persona: "experienced developer who shares hard-won lessons"
  style_notes:
    - "Use short, punchy sentences"
    - "Lead with a controversial or surprising take"
    - "End with a question or call-to-action"

content_pillars:
  - name: "hot_takes"
    description: "Contrarian opinions on tech trends"
    weight: 0.30
  - name: "practical_tips"
    description: "Actionable coding tips and tool recommendations"
    weight: 0.25
  - name: "career_insights"
    description: "Career advice, salary transparency"
    weight: 0.20
  - name: "ai_updates"
    description: "Latest AI/LLM developments explained simply"
    weight: 0.15
  - name: "startup_stories"
    description: "Lessons from building products"
    weight: 0.10

avoid_topics:
  - "political opinions unrelated to tech"
  - "cryptocurrency shilling"
```

The agent uses this config in every generation cycle to stay on-brand and on-topic.

## Tech Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| Agent Framework | [LangGraph](https://github.com/langchain-ai/langgraph) 0.3+ | Two-graph architecture with shared state |
| LLM | Claude Sonnet 4 via [langchain-anthropic](https://github.com/langchain-ai/langchain) | Pattern extraction, generation, ranking, analysis |
| State Persistence | LangGraph Checkpointer | Survives interrupts, restarts, crashes |
| Knowledge Base | LangGraph Store | Cross-pipeline memory with namespaces |
| Human-in-the-Loop | LangGraph `interrupt()` + [python-telegram-bot](https://github.com/python-telegram-bot/python-telegram-bot) | Pause graph â†’ Telegram notification â†’ resume on response |
| Research | [PRAW](https://praw.readthedocs.io/) + [Apify](https://apify.com/) | Reddit + Threads viral content discovery |
| Novelty Scoring | Cosine similarity on embeddings | Prevent repetitive content |
| Scheduling | [APScheduler](https://apscheduler.readthedocs.io/) | Creation 3x/day, learning 1x/day |
| API | [FastAPI](https://fastapi.tiangolo.com/) | Webhook receiver + status dashboard |
| Database | PostgreSQL (prod) / In-memory (dev) | Checkpoints, store, metrics |
| Validation | [Pydantic](https://docs.pydantic.dev/) v2 | Structured LLM output + data models |

## Tests

```bash
uv run pytest tests/ -v
```

```
tests/test_graphs/test_creation_pipeline.py::test_creation_pipeline_compiles       PASSED
tests/test_graphs/test_creation_pipeline.py::test_creation_pipeline_has_correct_nodes PASSED
tests/test_graphs/test_learning_pipeline.py::test_learning_pipeline_compiles       PASSED
tests/test_graphs/test_learning_pipeline.py::test_learning_pipeline_has_correct_nodes PASSED
tests/test_nodes/test_goal_check.py::test_goal_not_reached                         PASSED
tests/test_nodes/test_goal_check.py::test_goal_reached                             PASSED
tests/test_nodes/test_publishing.py::test_publish_post                             PASSED
tests/test_nodes/test_publishing.py::test_publish_post_no_selection                PASSED
tests/test_nodes/test_publishing.py::test_schedule_metrics_check                   PASSED
tests/test_nodes/test_research.py::test_research_returns_posts                     PASSED
tests/test_tools/test_embeddings.py::test_cosine_similarity_identical              PASSED
tests/test_tools/test_embeddings.py::test_cosine_similarity_orthogonal             PASSED
tests/test_tools/test_embeddings.py::test_mock_embeddings                          PASSED
tests/test_tools/test_embeddings.py::test_mock_embeddings_deterministic            PASSED
tests/test_tools/test_embeddings.py::test_novelty_score_no_history                 PASSED
tests/test_tools/test_embeddings.py::test_novelty_score_with_history               PASSED
tests/test_tools/test_threads_api.py::test_mock_follower_count                     PASSED
tests/test_tools/test_threads_api.py::test_mock_publish                            PASSED
tests/test_tools/test_threads_api.py::test_mock_metrics                            PASSED
tests/test_tools/test_threads_api.py::test_mock_user_posts                         PASSED

20 passed in 1.07s
```

## Production Deployment

```bash
# Start Postgres
docker compose up -d postgres

# Set production env
export ENV=production
export POSTGRES_URI=postgresql://agent:agent_password@localhost:5432/agent_db

# Or run everything in Docker
docker compose up -d
```

## Roadmap

- [x] Two-graph architecture (creation + learning)
- [x] Mock-first development (works without any API keys except Anthropic)
- [x] Multi-signal ranking (AI + history + novelty)
- [x] Human-in-the-loop via `interrupt()`
- [x] Configurable niche/voice/audience
- [ ] Real Threads API integration (pending API access)
- [ ] Telegram bot approval flow (end-to-end)
- [ ] LangSmith observability dashboard
- [ ] A/B testing (publish two variants, compare)
- [ ] Multi-platform support (X, Bluesky, LinkedIn)
- [ ] Web dashboard for strategy visualization

## Contributing

Contributions welcome! Some good first issues:

- Add more content pattern templates
- Implement real Reddit research with better filtering
- Add rate limiting and retry logic for API calls
- Build a web dashboard showing learning progress
- Add support for image/carousel posts

## License

MIT
